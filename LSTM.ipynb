{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X=df['comment_text']\n",
    "df_Y=df['target_dis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080220,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080220,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30)\n",
    "tokenizer.fit_on_texts(df_X)\n",
    "xtrain= tokenizer.texts_to_sequences(X_train)\n",
    "xtest= tokenizer.texts_to_sequences(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=30\n",
    "xtrain=pad_sequences(xtrain,padding='post', maxlen=maxlen)\n",
    "xtest=pad_sequences(xtest,padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BS, \n",
      "WE NEED TO STOP FOREIGNERS FROM TAKING AWAY OUR SOVEREIGNTY NOW !!\n",
      " AND YES VANCOUVER TOOK FAR  FAR TO LONG TO ACT !!! \n",
      "SALES IN VANCOUVER ARE DOWN 35 PERCENT AND THEY ARE KNOW BUYING UP TORONTO. \n",
      "WHY IS IT  THE LIBERALS HAVE NOOOO ISSUE TAXING THE PANTS OFF THE  WORKING MAN IN THIS PROVENCE  BUT WHEN IT COMES TO FOREIGNERS ROAD BLOCKS ARE PUT UP??\n",
      "[22 12 22  3 12 11  2  2 24 16  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[5])\n",
    "print(xtrain[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(5000, embedding_vecor_length, input_length=30))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programas\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 864176 samples, validate on 216044 samples\n",
      "Epoch 1/10\n",
      "864176/864176 [==============================] - 274s 316us/step - loss: 0.6820 - accuracy: 0.5598 - val_loss: 0.6804 - val_accuracy: 0.5640\n",
      "Epoch 2/10\n",
      "864176/864176 [==============================] - 276s 319us/step - loss: 0.6796 - accuracy: 0.5657 - val_loss: 0.6794 - val_accuracy: 0.5666\n",
      "Epoch 3/10\n",
      "864176/864176 [==============================] - 275s 319us/step - loss: 0.6781 - accuracy: 0.5676 - val_loss: 0.6782 - val_accuracy: 0.5674\n",
      "Epoch 4/10\n",
      "864176/864176 [==============================] - 275s 318us/step - loss: 0.6774 - accuracy: 0.5694 - val_loss: 0.6779 - val_accuracy: 0.5680\n",
      "Epoch 5/10\n",
      "864176/864176 [==============================] - 274s 317us/step - loss: 0.6767 - accuracy: 0.5705 - val_loss: 0.6783 - val_accuracy: 0.5676\n",
      "Epoch 6/10\n",
      "864176/864176 [==============================] - 274s 318us/step - loss: 0.6759 - accuracy: 0.5717 - val_loss: 0.6773 - val_accuracy: 0.5688\n",
      "Epoch 7/10\n",
      "864176/864176 [==============================] - 274s 317us/step - loss: 0.6750 - accuracy: 0.5736 - val_loss: 0.6777 - val_accuracy: 0.5700\n",
      "Epoch 8/10\n",
      "864176/864176 [==============================] - 274s 318us/step - loss: 0.6739 - accuracy: 0.5755 - val_loss: 0.6778 - val_accuracy: 0.5687\n",
      "Epoch 9/10\n",
      "864176/864176 [==============================] - 276s 319us/step - loss: 0.6727 - accuracy: 0.5777 - val_loss: 0.6780 - val_accuracy: 0.5676\n",
      "Epoch 10/10\n",
      "864176/864176 [==============================] - 274s 317us/step - loss: 0.6712 - accuracy: 0.5793 - val_loss: 0.6791 - val_accuracy: 0.5679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1846acb94c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, y_train, validation_data=(xtest, y_test), epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
